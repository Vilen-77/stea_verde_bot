from telegram import Update
from telegram.ext import CommandHandler, ContextTypes
import os
import requests
from handlers.meta_extractor import save_raw_meta_from_serp

# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
SERPAPI_KEY = os.getenv("SERPAPI_KEY")

# –†–∞–∑–±–æ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥—ã: +N, L, R
def parse_serp_args(args):
    query_parts = []
    count = 10  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    lang = "ro"
    region = "ro"

    for arg in args:
        if arg.startswith('+') and arg[1:].isdigit():
            count += int(arg[1:])
        elif arg.lower().startswith('l='):
            lang = arg[2:]
        elif arg.lower().startswith('r='):
            region = arg[2:]
        else:
            query_parts.append(arg)

    return ' '.join(query_parts), count, lang, region

# –ö–æ–º–∞–Ω–¥–∞ /serp
async def serp_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ /serp")
        return

    query, count, lang, region = parse_serp_args(context.args)
    await update.message.reply_text(f"üîç –ò—â—É: *{query}*\nüåê –Ø–∑—ã–∫: {lang}, –†–µ–≥–∏–æ–Ω: {region}\nüì¶ –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {count}", parse_mode="Markdown")

    params = {
        "engine": "google",
        "q": query,
        "api_key": SERPAPI_KEY,
        "hl": lang,
        "gl": region
    }

    try:
        response = requests.get("https://serpapi.com/search", params=params)
        data = response.json()
        results = data.get("organic_results", [])[:count]

        if not results:
            await update.message.reply_text("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return

        message = "üìÑ *–¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:*\n\n"
        
       


        for idx, res in enumerate(results, start=1):
            title = res.get("title", f"–†–µ–∑—É–ª—å—Ç–∞—Ç {idx}")
            link = res.get("link", "")
            message += f"‚Ä¢ [{title}]({link})\n"
            
            print(f"üåê –ü–∞—Ä—Å—é —Å—Å—ã–ª–∫—É: {link}")
            meta = fetch_meta(link)
            print(f"üß† META: {meta}")
            save_raw_meta(query, meta)
  

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞-–¥–∞–Ω–Ω—ã–µ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            from handlers.meta_extractor import save_raw_meta_from_serp

            title = res.get("title", "")
            snippet = res.get("snippet", "")
            save_raw_meta_from_serp(query, link, title, snippet)


        await update.message.reply_text(message, parse_mode="Markdown", disable_web_page_preview=True)

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ SerpAPI:", e)
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ SerpAPI.")

# –•–µ–Ω–¥–ª–µ—Ä –∫–æ–º–∞–Ω–¥—ã
handler = CommandHandler("serp", serp_command)
