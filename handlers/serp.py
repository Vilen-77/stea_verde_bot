from telegram import Update
from telegram.ext import CommandHandler, ContextTypes
import os
import requests
from handlers.meta_extractor import save_raw_meta_from_serp
from handlers.serp_table_builder import generate_serp_table
import shutil

# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
SERPAPI_KEY = os.getenv("SERPAPI_KEY")

# –†–∞–∑–±–æ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥—ã: +N, L, R
def parse_serp_args(args):
    query_parts = []
    count = 10  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    lang = "ro"
    region = "ro"

    for arg in args:
        if arg.startswith('+') and arg[1:].isdigit():
            count += int(arg[1:])
        elif arg.lower().startswith('l='):
            lang = arg[2:]
        elif arg.lower().startswith('r='):
            region = arg[2:]
        else:
            query_parts.append(arg)

    return ' '.join(query_parts), count, lang, region

# –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
def clear_serp_cache():
    folder = "serp_cache"
    if os.path.exists(folder):
        for filename in os.listdir(folder):
            file_path = os.path.join(folder, filename)
            try:
                os.remove(file_path)
            except Exception as e:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {file_path}: {e}")

# –ö–æ–º–∞–Ω–¥–∞ /serp
async def serp_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ /serp")
        return

    query, count, lang, region = parse_serp_args(context.args)
    await update.message.reply_text(f"üîç –ò—â—É: *{query}*\nüåê –Ø–∑—ã–∫: {lang}, –†–µ–≥–∏–æ–Ω: {region}\nüì¶ –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {count}", parse_mode="Markdown")

    params = {
        "engine": "google",
        "q": query,
        "api_key": SERPAPI_KEY,
        "hl": lang,
        "gl": region
    }

    try:
        response = requests.get("https://serpapi.com/search", params=params)
        data = response.json()
        results = data.get("organic_results", [])[:count]

        if not results:
            await update.message.reply_text("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return

        message = "üìÑ *–¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:*\n\n"

        for idx, res in enumerate(results, start=1):
            title = res.get("title", f"–†–µ–∑—É–ª—å—Ç–∞—Ç {idx}")
            link = res.get("link", "")
            snippet = res.get("snippet", "")

            message += f"‚Ä¢ [{title}]({link})\n"
            print(f"üåê –°–æ—Ö—Ä–∞–Ω—è—é SERP-–º–µ—Ç–∞: {link}")
            save_raw_meta_from_serp(query, link, title, snippet)

        await update.message.reply_text(message, parse_mode="Markdown", disable_web_page_preview=True)

        table_path = generate_serp_table()
        await update.message.reply_document(document=open(table_path, "rb"))

        clear_serp_cache()

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ SerpAPI:", e)
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ SerpAPI.")

# –•–µ–Ω–¥–ª–µ—Ä –∫–æ–º–∞–Ω–¥—ã
handler = CommandHandler("serp", serp_command)
