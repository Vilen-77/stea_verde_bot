import os
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
from openai import OpenAI

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(api_key=OPENAI_API_KEY)

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø stea_verde_bot ü§ñ. –ù–∞–ø–∏—à–∏ /semantics <—Ç–µ–º–∞>, –∏ —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ.")

# –ö–æ–º–∞–Ω–¥–∞ /semantics <–∑–∞–ø—Ä–æ—Å>
async def semantics(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = ' '.join(context.args)
    if not query:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏ –∫–ª—é—á–µ–≤—É—é —Ñ—Ä–∞–∑—É –ø–æ—Å–ª–µ /semantics.")
        return

    prompt = f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ –∏–∑ 30 –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑ –ø–æ —Ç–µ–º–µ '{query}', —Ä–∞–∑–¥–µ–ª–∏ –∏—Ö –ø–æ –∏–Ω—Ç–µ–Ω—Ç—É (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ, –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ, —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ) –∏ –æ—Ñ–æ—Ä–º–∏ —Å–ø–∏—Å–∫–æ–º."

    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        result = response.choices[0].message.content.strip()
        await update.message.reply_text(result)

    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞: {str(e)}")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("semantics", semantics))
    app.run_polling()

if __name__ == "__main__":
    main()
